# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ASd56EYovgB8BpwP4gXaFVX0rQIPd9vm
"""

# app.py
from fastapi import FastAPI
from pydantic import BaseModel
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.schema import Document
import os
import pandas as pd

app = FastAPI()

# Load dữ liệu và khởi tạo mô hình
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    raise ValueError("Thiếu biến môi trường OPENAI_API_KEY. Vui lòng cấu hình trong Render.")

# Đọc CSV
df = pd.read_csv("HANH_VI.csv")
texts = df['hanh_vi'].tolist()
chunks = [Document(page_content=row) for row in texts]

embedding_model = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(documents=chunks, embedding=embedding_model, persist_directory="./chroma_db")
vectorstore.persist()

llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7)

prompt_template = PromptTemplate(
    input_variables=["context", "question"],
    template="""
Bạn là chuyên gia tư vấn hành vi trẻ em. Dưới đây là một số thông tin liên quan:

{context}

Câu hỏi: {question}

Trả lời như một chuyên gia, đang tâm sự với người hỏi.
"""
)

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever(search_type="similarity", k=3),
    chain_type="stuff",
    chain_type_kwargs={"prompt": prompt_template},
    return_source_documents=True
)

class Query(BaseModel):
    question: str

@app.post("/chat")
async def chat(query: Query):
    result = qa_chain({"query": query.question})
    return {"answer": result["result"]}
